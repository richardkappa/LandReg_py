{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"D:/GeoData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land Registry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LReg_Names = ['Transaction_unique_identifier', 'Price', 'Date_of_Transfer', 'Postcode', 'Property_Type', \n",
    "              'Old_New', 'Duration', 'PAON', 'SAON', 'Street', 'Locality', 'Town_City', 'District', 'County', \n",
    "              'PPDCategory_Type', 'Record_Status_monthly_file_only']\n",
    "\n",
    "LReg_Data2020 = pd.read_csv(root_path + \"LandReg/pp-2020.csv\", names = LReg_Names) \n",
    "LReg_Data2021 = pd.read_csv(root_path + \"LandReg/pp-2021.csv\", names = LReg_Names) \n",
    "\n",
    "LReg_Data = pd.concat([LReg_Data2020,LReg_Data2021])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaPTAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rail_names_kp = ['TiplocCode', 'CrsCode', 'StationName', 'Easting', 'Northing']\n",
    "np_ferry_names_kp = ['FerryCode', 'Name', 'Easting', 'Northing']\n",
    "np_bus_names_kp = ['CommonName', 'Easting', 'Northing']\n",
    "\n",
    "RailwayStations = pd.read_csv(root_path + \"NaPTANcsv/RailReferences.csv\", usecols=np_rail_names_kp) \n",
    "FerryTerminals = pd.read_csv(root_path + \"NaPTANcsv/FerryReferences.csv\", usecols=np_ferry_names_kp) \n",
    "BusStops = pd.read_csv(root_path + \"NaPTANcsv/Stops.csv\", usecols=np_bus_names_kp, encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road Accidents Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Road_Accidents_names_kp = ['accident_year', 'accident_reference', 'location_easting_osgr', 'location_northing_osgr', 'police_force', 'accident_severity', 'number_of_vehicles', 'number_of_casualties', 'date', 'day_of_week', 'time']\n",
    "\n",
    "Road_Accidents = pd.read_csv(root_path + \"RoadSafety/dft-road-casualty-statistics-accident-2020.csv\", usecols=Road_Accidents_names_kp, low_memory=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the date into a date\n",
    "LReg_Data['Date_of_Transfer'] = pd.to_datetime(LReg_Data['Date_of_Transfer'], errors='ignore')\n",
    "\n",
    "#Calculate the year of transfer\n",
    "LReg_Data[\"Year_Of_Transfer\"] = pd.DatetimeIndex(LReg_Data['Date_of_Transfer']).year\n",
    "\n",
    "#remove the spaces from the postcode\n",
    "LReg_Data[\"Postcode_NS\"] = LReg_Data[\"Postcode\"].astype(str).str.replace(\" \",\"\")\n",
    "\n",
    "#Cols to keep\n",
    "keep_cols = ['Price', 'Date_of_Transfer', 'Year_Of_Transfer', 'Postcode_NS', 'Property_Type', 'Old_New', 'Duration']\n",
    "LReg_Data = LReg_Data.loc[:,keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "National statistics udprn file (only for house locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['uprn', 'gridgb1e', 'gridgb1n', 'pcds']\n",
    "file = os.listdir(\"D:/GeoData/NSUL_OCT_2020/Data\")\n",
    "path = [os.path.join(\"D:/GeoData/NSUL_OCT_2020/Data\", i) for i in file if \".csv\" in i]\n",
    "\n",
    "NSUL_Data = pd.concat([pd.read_csv(i,  usecols=keep_cols) for i in path])\n",
    "\n",
    "NSUL_Data[\"Postcode_NS\"] = NSUL_Data[\"pcds\"].astype(str).str.replace(\" \",\"\")\n",
    "\n",
    "house_count = NSUL_Data.loc[:, ['Postcode_NS', 'uprn']].groupby(['Postcode_NS']).size().reset_index(name='Houses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "National statistics postcode lookup file and references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Dir = \"NSPL_NOV_2020_UK/\"\n",
    "NSPL_Filename = \"Data/NSPL_NOV_2020_UK.csv\"\n",
    "\n",
    "NSPL_Data = pd.read_csv(root_path + NSPL_Dir + NSPL_Filename, low_memory = False) \n",
    "\n",
    "#Not keeping all of the columns, for fairly arbitrary reasons\n",
    "keep_cols = ['pcd', 'oseast1m', 'osnrth1m', 'osgrdind', 'oa11', 'cty', 'ced', 'laua', 'ward', 'hlthau', 'nhser', 'ctry', \n",
    "             'rgn', 'pcon', 'teclec', 'ttwa', 'pct', 'nuts', 'park', 'lsoa11', 'msoa11', 'ccg', 'bua11', 'buasd11', \n",
    "             'ru11ind', 'pfa', 'calncv', 'stp', 'imd']  \n",
    "\n",
    "NSPL_Data = NSPL_Data.loc[:,keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Data[\"Postcode_NS\"] = NSPL_Data[\"pcd\"].astype(str).str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlookup(filename, keep):\n",
    "    lookup = pd.read_csv(root_path + NSPL_Dir + \"Documents/\" + filename)\n",
    "    lookup = lookup.loc[:,keep]\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa11 = getlookup('2011 Census Output Area Classification Names and Codes UK.csv', ['OAC11', 'Supergroup', 'Group', 'Subgroup'])\n",
    "cty = getlookup('County names and codes UK as at 04_20_NSPL.csv', ['CTY20CD', 'CTY20NM'])\n",
    "ced = getlookup('County Electoral Division names and codes EN as at 12_17.csv', ['CED17CD', 'CED17NM'])\n",
    "laua = getlookup('LA_UA names and codes UK as at 04_20.csv', ['LAD20CD', 'LAD20NM'])\n",
    "ward = getlookup('Ward names and codes UK as at 12_19.csv', ['WD19CD', 'WD19NM'])\n",
    "hlthau = getlookup('HLTHAU names and codes UK as at 04_19.csv', ['HLTHAUCD', 'HLTHAUNM'])\n",
    "nhser = getlookup('NHSER names and codes EN as at 04_19.csv', ['NHSER19CD', 'NHSER19NM'])\n",
    "ctry = getlookup('Country names and codes UK as at 08_12.csv', ['CTRY12CD', 'CTRY12NM'])\n",
    "rgn = getlookup('Region names and codes EN as at 12_10 (GOR).csv', ['GOR10CD', 'GOR10NM', 'GOR10NMW', 'GOR10CDO'])\n",
    "pcon = getlookup('Westminster Parliamentary Constituency names and codes UK as at 12_14.csv', ['PCON14CD', 'PCON14NM'])\n",
    "teclec = getlookup('TECLEC names and codes UK as at 12_16.csv', ['TECLECCD', 'TECLECNM', 'TECLECCDO'])\n",
    "ttwa = getlookup('TTWA names and codes UK as at 12_11 v5.csv', ['TTWA11CD', 'TTWA11NM'])\n",
    "pct = getlookup('PCT names and codes UK as at 04_19.csv', ['PCTCD', 'PCTNM', 'PCTCDO'])\n",
    "nuts = getlookup('LAU2 names and codes UK as at 12_18.csv', ['LAU218CD', 'LAU218NM'])\n",
    "park = getlookup('National Park names and codes GB as at 08_16.csv', ['NPARK16CD', 'NPARK16NM'])\n",
    "lsoa11 = getlookup('LSOA (2011) names and codes UK as at 12_12.csv', ['LSOA11CD', 'LSOA11NM'])\n",
    "msoa11 = getlookup('MSOA (2011) names and codes UK as at 12_12.csv', ['MSOA11CD', 'MSOA11NM'])\n",
    "ccg = getlookup('CCG names and codes UK as at 04_20.csv', ['CCG20CD', 'CCG20NM', 'CCG20CDH', 'CCG20NMW'])\n",
    "bua11 = getlookup('BUA_names and codes UK as at 12_13.csv', ['BUA13CD', 'BUA13NM'])\n",
    "buasd11 = getlookup('BUASD_names and codes UK as at 12_13.csv', ['BUASD13CD', 'BUASD13NM'])\n",
    "ru11ind = getlookup('Rural Urban (2011) Indicator names and codes GB as at 12_16.csv', ['RU11IND', 'RU11NM'])\n",
    "pfa = getlookup('PFA names and codes GB as at 12_15.csv', ['PFA15CD', 'PFA15NM'])\n",
    "calncv     = getlookup('CALNCV names and codes EN as at 07_18.csv', ['CALNCV18CD', 'CALNCV18NM'])\n",
    "stp = getlookup('STP names and codes EN as at 04_20.csv', ['STP20CD', 'STP20NM', 'STP20CDH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Data = NSPL_Data.merge(house_count, left_on='Postcode_NS', right_on='Postcode_NS', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(oa11, left_on='oa11', right_on='OAC11', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(cty, left_on='cty', right_on='CTY20CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ced, left_on='ced', right_on='CED17CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(laua, left_on='laua', right_on='LAD20CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ward, left_on='ward', right_on='WD19CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(hlthau, left_on='hlthau', right_on='HLTHAUCD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(nhser, left_on='nhser', right_on='NHSER19CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ctry, left_on='ctry', right_on='CTRY12CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(rgn, left_on='rgn', right_on='GOR10CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(pcon, left_on='pcon', right_on='PCON14CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(teclec, left_on='teclec', right_on='TECLECCD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ttwa, left_on='ttwa', right_on='TTWA11CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(pct, left_on='pct', right_on='PCTCD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(nuts, left_on='nuts', right_on='LAU218CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(park, left_on='park', right_on='NPARK16CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(lsoa11, left_on='lsoa11', right_on='LSOA11CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(msoa11, left_on='msoa11', right_on='MSOA11CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ccg, left_on='ccg', right_on='CCG20CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(bua11, left_on='bua11', right_on='BUA13CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(buasd11, left_on='buasd11', right_on='BUASD13CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(ru11ind, left_on='ru11ind', right_on='RU11IND', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(pfa, left_on='pfa', right_on='PFA15CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(calncv , left_on='calncv', right_on='CALNCV18CD', how='left')\n",
    "NSPL_Data = NSPL_Data.merge(stp, left_on='stp', right_on='STP20CD', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_RawNames = ['OAC11', 'CTY20CD', 'CED17CD', 'LAD20CD', 'WD19CD', 'HLTHAUCD', 'NHSER19CD', 'CTRY12CD', 'GOR10CD', \n",
    "                 'PCON14CD', 'TECLECCD', 'TTWA11CD', 'PCTCD', 'LAU218CD', 'NPARK16CD', 'LSOA11CD', 'MSOA11CD', 'CCG20CD', \n",
    "                 'BUA13CD', 'BUASD13CD', 'RU11IND', 'PFA15CD', 'CALNCV18CD', 'STP20CD']\n",
    "\n",
    "NSPL_LookupNames = ['Supergroup', 'Group', 'Subgroup', 'CTY20NM', 'CED17NM', 'LAD20NM', 'WD19NM', 'HLTHAUNM', 'NHSER19NM', \n",
    "                    'CTRY12NM', 'GOR10NM', 'GOR10NMW', 'GOR10CDO', 'PCON14NM', 'TECLECNM', 'TECLECCDO', 'TTWA11NM', \n",
    "                    'PCTNM', 'PCTCDO', 'LAU218NM', 'NPARK16NM', 'LSOA11NM', 'MSOA11NM', 'CCG20NM', 'CCG20CDH', 'CCG20NMW',\n",
    "                    'BUA13NM', 'BUASD13NM', 'RU11NM', 'PFA15NM', 'CALNCV18NM', 'STP20NM', 'STP20CDH']\n",
    "\n",
    "Base_Names = [\"Postcode_NS\", \"oseast1m\", \"osnrth1m\"]\n",
    "\n",
    "NSPL_Data = NSPL_Data.loc[:,Base_Names + NSPL_RawNames + NSPL_LookupNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined = LReg_Data.merge(NSPL_Data, left_on = \"Postcode_NS\", right_on = \"Postcode_NS\", how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Data.to_pickle(root_path + 'WorkingData/' + 'NSPL_Data.pickle')\n",
    "Combined.to_pickle(root_path + 'WorkingData/' + 'LandReg.pickle')\n",
    "NSUL_Data.to_pickle(root_path + 'WorkingData/' + 'NSUL_Data.pickle')\n",
    "BusStops.to_pickle(root_path + 'WorkingData/' + 'BusStops_Data.pickle')\n",
    "FerryTerminals.to_pickle(root_path + 'WorkingData/' + 'FerryTerminals_Data.pickle')\n",
    "RailwayStations.to_pickle(root_path + 'WorkingData/' + 'RailwayStations_Data.pickle')\n",
    "Road_Accidents.to_pickle(root_path + 'WorkingData/' + 'Road_Accidents_Data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
