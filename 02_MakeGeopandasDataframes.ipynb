{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"D:/GeoData/\"\n",
    "Main_CRS = \"EPSG:27700\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape_Loc = {\n",
    "    'All_GB' : root_path + \"Countries__December_2019__Boundaries_UK_BFC-shp/Countries__December_2019__Boundaries_UK_BFC.shp\",\n",
    "    'National_Parks' : root_path + \"National_Parks__December_2019__GB_BFE-shp/National_Parks__December_2019__GB_BFE.shp\",\n",
    "    'LocalAuthorities' : root_path + \"Local_Authority_Districts__May_2020__Boundaries_UK_BFC-shp/Local_Authority_Districts__May_2020__Boundaries_UK_BFC.shp\",\n",
    "    'LSOA' : root_path + \"Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2-shp/Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2.shp\",\n",
    "    'GreenSpace' : root_path + \"opgrsp_essh_gb/OS Open Greenspace (ESRI Shape File) GB/data/GB_GreenspaceSite.shp\",\n",
    "    'Rivers' : root_path + \"oprvrs_essh_gb/data/WatercourseLink.shp\",\n",
    "    'Railway_Lines' : root_path + \"strtgi_essh_gb/data/railway_line.shp\",\n",
    "    'Woodland_Region' : root_path + \"strtgi_essh_gb/data/woodland_region.shp\",\n",
    "    'Urban_Region' : root_path + \"strtgi_essh_gb/data/urban_region.shp\",\n",
    "    'Foreshor_Region' : root_path + \"strtgi_essh_gb/data/foreshor_region.shp\",\n",
    "    'Ferry_Line' : root_path + \"strtgi_essh_gb/data/ferry_line.shp\",\n",
    "    'Coastline' : root_path + \"strtgi_essh_gb/data/coastline.shp\" ,\n",
    "    'Gridlines' : root_path + \"strtgi_essh_gb/data/gridlines.shp\",\n",
    "    'Lakes' : root_path + \"strtgi_essh_gb/data/lakes_region.shp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Maps = dict((k, gpd.read_file(v).to_crs(Main_CRS)) for k, v in Shape_Loc.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.listdir(\"D:\\GeoData\\oproad_essh_gb\\data\")\n",
    "\n",
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"RoadLink.shp\" in i]\n",
    "\n",
    "All_Maps['Road_Link'] = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path], \n",
    "                        ignore_index=True), crs=Main_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"MotorwayJunction.shp\" in i]\n",
    "\n",
    "All_Maps['MotorwayJunctions'] = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path], \n",
    "                        ignore_index=True), crs=Main_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Maps['Motorway'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"Motorway\"]\n",
    "All_Maps['A_Roads'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"A Road\"]\n",
    "All_Maps['B_Roads'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"B Road\"]\n",
    "All_Maps['Other_roads'] = All_Maps['Road_Link'][~All_Maps['Road_Link'][\"class\"].isin([ \"Motorway\", \"A Road\", \"B Road\"])]\n",
    "\n",
    "#del All_Maps['Road_Link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSPL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Data = pd.read_pickle(root_path + 'WorkingData/' + 'NSPL_Data.pickle')\n",
    "All_Maps['NSPL_gdf'] = gpd.GeoDataFrame(NSPL_Data, geometry=gpd.points_from_xy(NSPL_Data.oseast1m, NSPL_Data.osnrth1m), crs=Main_CRS)\n",
    "\n",
    "del NSPL_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land Registry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LandReg = pd.read_pickle(root_path + 'WorkingData/' + 'LandReg.pickle')\n",
    "All_Maps['LandReg_gdf'] = gpd.GeoDataFrame(LandReg, geometry=gpd.points_from_xy(LandReg.oseast1m, LandReg.osnrth1m), crs=Main_CRS)\n",
    "\n",
    "del LandReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of mapping data here. My computer isn't that powerful so we need to subset the data. I've chosen a list of points and the code below clips the data to squares around these points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for clipping and saving the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePolygon(centre, sq_sz, inp_crs):\n",
    "    mnx = centre[0]-(sq_sz/2)\n",
    "    mny = centre[1]-(sq_sz/2)\n",
    "    mxx = centre[0]+(sq_sz/2)\n",
    "    mxy = centre[1]+(sq_sz/2)\n",
    "    polygon =Polygon([(mnx, mny), (mnx,mxy), (mxx,mxy), (mxx,mny), (mnx, mny)])\n",
    "    poly_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=inp_crs)\n",
    "    return poly_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(name , obj, extra=\"\"):\n",
    "    with open(root_path + 'WorkingData/' + extra + name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open(root_path + 'WorkingData/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClipAndSave(name, centre, sq_sz, crs, extra):\n",
    "    print(name)\n",
    "    poly = MakePolygon(centre, sq_sz, crs)\n",
    "    maps = dict((k, gpd.clip(v, poly)) for k, v in All_Maps.items())\n",
    "    save_obj(name , maps, extra)\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip and save the maps for specific locations. Save at 5km^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj('All_Maps' , All_Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyLocations = {'Grasmere': [334692 , 506545],\n",
    "                'South_London' : [535493, 171250],\n",
    "                'Loch_Lomond' : [238450 , 690986],\n",
    "                'Furness' : [326877 , 474372],\n",
    "                'Croydon' : [532621 , 165313],\n",
    "                'StPauls' : [532052 , 181145],\n",
    "                'M25' : [503078 , 178200],\n",
    "                'M4_junct' : [519377 , 178360],\n",
    "                'M6_Junctions' : [357659 , 425462],\n",
    "                'Kendal': [353086 , 492882],\n",
    "                'Milford Haven': [190649 , 205747],\n",
    "                'Birmingham':[409295 , 290319],\n",
    "                'Euston':[529947 , 182697],\n",
    "                'Southampton'[441934 , 111013],\n",
    "                'Windermere': [341217 , 498029]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawkshead\n",
      "South_London\n",
      "Loch_Lomond\n",
      "Furness\n",
      "Croydon\n",
      "StPauls\n",
      "ElephantCastle\n",
      "M4_junct\n",
      "M6_Junctions\n",
      "Kendal\n",
      "Milford Haven\n",
      "Birmingham\n",
      "Euston\n"
     ]
    }
   ],
   "source": [
    "ClippedMaps_5k = dict((k, ClipAndSave(k, v, 5000, Main_CRS, \"Clipped5k_\")) for k, v in KeyLocations.items())\n",
    "save_obj('ClippedMaps_5k' , ClippedMaps_5k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
