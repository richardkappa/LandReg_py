{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"D:/GeoData/\"\n",
    "Main_CRS = \"EPSG:27700\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape_Loc = {\n",
    "    'All_GB' : root_path + \"Countries__December_2019__Boundaries_UK_BFC-shp/Countries__December_2019__Boundaries_UK_BFC.shp\",\n",
    "    'National_Parks' : root_path + \"National_Parks__December_2019__GB_BFE-shp/National_Parks__December_2019__GB_BFE.shp\",\n",
    "    'LocalAuthorities' : root_path + \"Local_Authority_Districts__May_2020__Boundaries_UK_BFC-shp/Local_Authority_Districts__May_2020__Boundaries_UK_BFC.shp\",\n",
    "    'LSOA' : root_path + \"Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2-shp/Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2.shp\",\n",
    "    'GreenSpace' : root_path + \"opgrsp_essh_gb/OS Open Greenspace (ESRI Shape File) GB/data/GB_GreenspaceSite.shp\",\n",
    "    'Rivers' : root_path + \"oprvrs_essh_gb/data/WatercourseLink.shp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Maps = dict((k, gpd.read_file(v).to_crs(Main_CRS)) for k, v in Shape_Loc.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.listdir(\"D:\\GeoData\\oproad_essh_gb\\data\")\n",
    "\n",
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"RoadLink.shp\" in i]\n",
    "\n",
    "All_Maps['Road_Link'] = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path], \n",
    "                        ignore_index=True), crs=Main_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"MotorwayJunction.shp\" in i]\n",
    "\n",
    "All_Maps['MotorwayJunctions'] = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path], \n",
    "                        ignore_index=True), crs=Main_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Maps['Motorway'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"Motorway\"]\n",
    "All_Maps['A_Roads'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"A Road \"]\n",
    "All_Maps['B_Roads'] = All_Maps['Road_Link'][All_Maps['Road_Link']['class'] == \"B Road\"]\n",
    "All_Maps['Other_roads'] = All_Maps['Road_Link'][~All_Maps['Road_Link'][\"class\"].isin([ \"Motorway\", \"A Road\", \"B Road\"])]\n",
    "\n",
    "#del All_Maps['Road_Link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSPL_Data = pd.read_pickle(root_path + 'WorkingData/' + 'NSPL_Data.pickle')\n",
    "All_Maps['NSPL_gdf'] = gpd.GeoDataFrame(NSPL_Data, geometry=gpd.points_from_xy(NSPL_Data.oseast1m, NSPL_Data.osnrth1m), crs=Main_CRS)\n",
    "\n",
    "del NSPL_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LandReg = pd.read_pickle(root_path + 'WorkingData/' + 'LandReg.pickle')\n",
    "All_Maps['LandReg_gdf'] = gpd.GeoDataFrame(LandReg, geometry=gpd.points_from_xy(LandReg.oseast1m, LandReg.osnrth1m), crs=Main_CRS)\n",
    "\n",
    "del LandReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UDPRNs = pd.read_pickle(root_path + 'WorkingData/' + 'NSUL_Data.pickle')\n",
    "#All_Maps['UDPRNs_gdf'] = gpd.GeoDataFrame(UDPRNs, geometry=gpd.points_from_xy(UDPRNs.gridgb1e, UDPRNs.gridgb1n), crs=Main_CRS)\n",
    "\n",
    "#del UDPRNs\n",
    "#All_Maps['UDPRNs_gdf'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for clipping and saving the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePolygon(centre, sq_sz, inp_crs):\n",
    "    mnx = centre[0]-(sq_sz/2)\n",
    "    mny = centre[1]-(sq_sz/2)\n",
    "    mxx = centre[0]+(sq_sz/2)\n",
    "    mxy = centre[1]+(sq_sz/2)\n",
    "    polygon =Polygon([(mnx, mny), (mnx,mxy), (mxx,mxy), (mxx,mny), (mnx, mny)])\n",
    "    poly_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=inp_crs)\n",
    "    return poly_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(name , obj, extra=\"\"):\n",
    "    with open(root_path + 'WorkingData/' + extra + name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open(root_path + 'WorkingData/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClipAndSave(name, centre, sq_sz, crs, extra):\n",
    "    print(name)\n",
    "    poly = MakePolygon(centre, sq_sz, crs)\n",
    "    maps = dict((k, gpd.clip(v, poly)) for k, v in All_Maps.items())\n",
    "    save_obj(name , maps, extra)\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip and save the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj('All_Maps' , All_Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyLocations = {'Sydenham' : [535493, 171250],\n",
    "                'Cumbria' : [326877 , 474372],\n",
    "                'Croydon' : [532621 , 165313],\n",
    "                'StPauls' : [532052 , 181145],\n",
    "                'ElephantCastle' : [531958 , 179077],\n",
    "                'M4_junct' : [519377 , 178360],\n",
    "                'M6_Junctions' : [357659 , 425462]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sydenham\n"
     ]
    }
   ],
   "source": [
    "ClippedMaps_5k = dict((k, ClipAndSave(k, v, 5000, Main_CRS, \"Clipped5k_\")) for k, v in KeyLocations.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj('ClippedMaps_5k' , ClippedMaps_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMap(Mapset):\n",
    "    ax = Mapset['All_GB'].plot(figsize=(20,20), color='white', edgecolor='grey')\n",
    "\n",
    "    Mapset['Other_roads'].plot(ax=ax, color='black', linewidth=0.3)\n",
    "    Mapset['Motorway'].plot(ax=ax, color='black', linewidth=3)\n",
    "    Mapset['A_Roads'].plot(ax=ax, color='black', linewidth=2)\n",
    "    Mapset['B_Roads'].plot(ax=ax, color='black', linewidth=1)\n",
    "    Mapset['Rivers'].plot(ax=ax, color='blue', linewidth=0.2, alpha=1)\n",
    "    Mapset['National_Parks'].plot(ax=ax, color='green', alpha=0.5)\n",
    "    Mapset['GreenSpace'].plot(ax=ax, color='green', alpha=0.7)\n",
    "\n",
    "    Mapset['LandReg_gdf'].plot(ax=ax, color='black', alpha=1, markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMap(ClippedMaps_5k[\"Cumbria\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMap(ClippedMaps_5k[\"M6_Junctions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMap(ClippedMaps_5k[\"Sydenham\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMap(ClippedMaps_5k[\"M4_junct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next tasks\n",
    "\n",
    "* Blog the above\n",
    "* Add crashes from stat 19\n",
    "* Add police crime data\n",
    "* Add raster for some sort of geology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
